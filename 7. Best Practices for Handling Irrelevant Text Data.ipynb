{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3aff6b0-26ce-4c74-a1b0-91d4cf285869",
   "metadata": {},
   "source": [
    "# 1 . Robust Data Processing\n",
    "\n",
    "robust data preprocessing, which involves handling irrelevant text data by cleaning and transforming the data into a format that can be effectively \n",
    "analyzed. This might mean undertaking several steps, such as tokenization, stopword removal, stemming or lemmatization, and noise removal from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7025099-4c28-4b39-88ea-db721dbb1372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "import re\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1f068b-8ffa-4d27-8afb-6c875df5bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens_without_stopwords = [token for token in tokens if token.lower() not in stop_words]\n",
    "    combined_text = ' '.join(tokens_without_stopwords) \n",
    "    processed_text = re.sub(r'[^\\w\\s]', '', combined_text)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32abe143-f6fc-45bd-b0a2-b283e7fb79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I'll be going to the park, and we're meeting at 3 o'clock. It's a beautiful day!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8880b80e-c51a-4d61-aa8f-d12ebf326be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going park meeting 3 clock beautiful day\n"
     ]
    }
   ],
   "source": [
    "preprocessed_text = preprocess_text(text)\n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72e7e7-8489-4bc3-b9fe-a62bc1c0fb1a",
   "metadata": {},
   "source": [
    "# Iterative Refinement\n",
    "\n",
    "Iterative refinement is a powerful technique for improving text data quality by progressively enhancing it without losing valuable information. \n",
    "In the following code example, we utilize Python’s spaCy library to demonstrate iterative refinement’s effectiveness in removing stopwords and \n",
    "punctuations from a short corpus of text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ea984c-80c6-4732-a9dc-274121c4166b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e03a8c-09a5-459d-85f8-371ae84160a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"We'll check out our exclusive sale!\",\n",
    "    \"You'll earn money from home with this amazing opportunity!\",\n",
    "    \"Get rid of junk emails and spam.\",\n",
    "    \"Unsubscribe from irrelevant newsletters.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a667fb4a-af18-4a0e-81a2-6c6089494f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    tokens = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens_without_stopwords = [token for token in tokens if token.lower() not in stop_words]\n",
    "    combined_text = ' '.join(tokens_without_stopwords)\n",
    "    return combined_text\n",
    "    \n",
    "def remove_punctuations(text):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5091c657-7682-46f2-8f8f-04e9fcdc8b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original corpus: [\"We'll check out our exclusive sale!\", \"You'll earn money from home with this amazing opportunity!\", 'Get rid of junk emails and spam.', 'Unsubscribe from irrelevant newsletters.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original corpus:\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30d1abfc-9616-485a-9b3e-42e54aea3b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 2: ['check exclusive sale', 'earn money home amazing opportunity', 'Get rid junk emails spam', 'Unsubscribe irrelevant newsletters']\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    refined_corpus = []\n",
    "    for doc in corpus:\n",
    "        cleaned_text = remove_stopwords(doc)\n",
    "        cleaned_text = remove_punctuations(cleaned_text)\n",
    "        refined_corpus.append(cleaned_text)\n",
    "    corpus = refined_corpus\n",
    "print(f\"\\nIteration {i}: {corpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9334f9-c5ec-48cf-8705-fef1e63cbd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
